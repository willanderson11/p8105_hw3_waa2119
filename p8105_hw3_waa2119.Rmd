---
title: "p8105_hw3_waa2119"
author: "William Anderson"
date: "2022-10-12"
output: github_document
---


```{r, message = FALSE}

library(tidyverse)
library(dplyr)
library(p8105.datasets)


knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 2

Loading the accelerometer data

```{r}
accel_data = 
  read_csv("HW3_Data/accel_data.csv") %>%
  
  janitor::clean_names() %>%
  
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "activity_count",
    names_prefix = "activity_", 
    values_to = "acceleration_values") %>%
  
  mutate(type_of_day = 
              ifelse(day == "Saturday" | day == "Sunday", "Weekend", "Weekday"))
  

head(accel_data, 10)
```

This data set is comprised of accelerometer data which during observation periods measures “activity counts” in a short period; one-minute intervals are common. Because accelerometers can be worn comfortably and unobtrusively, they produce around-the-clock observations.

This data set contains five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF)


The variables in this accelerometer data set are `r colnames(accel_data)`

The number of observations are `r count(accel_data)`

The dimensions of the data set are `r dim(accel_data)`


Now we aggregate across minutes to create a total activity variable for each day, and create a table showing these values

```{r}
accel_data_summary =
  
  accel_data %>%
  
  mutate(
    day = as.factor(day)
    ) %>%
  
  mutate(day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  
  group_by(day, week) %>%
  
  summarize(total_activity_levels = sum(acceleration_values), .groups = "drop") %>%
  
  ungroup()

head(accel_data_summary, 10)

```

Now we plot to observe any trends

```{r}
ggplot(accel_data_summary, aes(x = day, y = total_activity_levels, color = week, group = week)) + 
  
  geom_line() + 
  
  geom_point()
```

Activity levels were consistently increasing from Tuesday - Wednesday for each week, Saturdays for weeks 4 and 5 had no activity level


## Problem 3

Loading the NY NOAA data set
```{r}

data("ny_noaa")

head(ny_noaa, 10)
```

This data set from the National Oceanic and Atmospheric Association (NOAA) and contains records from over 100,000 stations in 180 countries and territories. NCEI provides numerous daily variables, including maximum and minimum temperature, total daily precipitation, snowfall, and snow depth; however, about one half of the stations report precipitation only. Both the record length and period of record vary by station and cover intervals ranging from less than a year to more than 175 years.

Our data set specifically contains observations within the state of New York

The size of the data is `r dim(ny_noaa)`

The structure of this data is `r str(ny_noaa)`

The key variables are `r colnames(ny_noaa)`

The id corresponds to the weather station ID from which the data was recorded, date is the date of observation, prcp is precipitation in tenths of mm, snow is recorded snowfall in mm, snwd is snow depth in mm, tmax is maximum temperature in tenths of celsius, tmin is minimum temperature in tenths of celsius

Some entries in the prcp, snow, snwd, tmax, and tmin values are missing which does not allow for a robust analysis of this data

Now we will clean the data

```{r}
ny_noaa_tidy = 
  
  sample_n(ny_noaa, 5000) %>%
  
  janitor::clean_names() %>%
  
  separate(date, into = c("Year", "Month", "Day")) %>%
  
  mutate(tmax = as.numeric(tmax), tmin = as.numeric(tmin), Year = as.numeric(Year), Month = as.numeric(Month), Day = as.numeric(Day)) %>%
  
   mutate(Month = month.name[Month]) %>%
  
  mutate(tmax = tmax * 10, 
         tmin = tmin * 10, 
         prcp = prcp * 10)


```

For snowfall, what are the most commonly observed values? Why?

Make a two-panel plot showing the average max temperature in January and in July in each station across years. Is there any observable / interpretable structure? Any outliers?


```{r}
ny_noaa_summary =
  ny_noaa_tidy %>%
  
  filter(Month %in% c("January", "July")) %>%
  
  group_by(id, Year, Month) %>%
  
  summarize(mean_tmax = mean(tmax), na.rm = TRUE)

ggplot(ny_noaa_summary, aes(x = Year, y = mean_tmax, group = id)) + 
    geom_line() + 
    facet_grid(. ~ Month) 

```


